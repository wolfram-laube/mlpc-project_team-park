{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533d40b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T14:54:20.904395Z",
     "start_time": "2024-05-20T14:54:20.895964Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Any additional libraries needed\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Ensure the 'fig' directory exists\n",
    "import os\n",
    "os.makedirs('fig', exist_ok=True)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c66325eb",
   "metadata": {},
   "source": [
    "# 1. Data Split\n",
    "\n",
    "## 1.a Description of Data Split for Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1caf3597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T11:26:47.448596Z",
     "start_time": "2024-05-20T11:26:46.932316Z"
    }
   },
   "source": [
    "# Load your dataset\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Split the dataset\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Description of the data split\n",
    "print(f'Training set size: {len(train_data)}')\n",
    "print(f'Validation set size: {len(val_data)}')\n",
    "print(f'Test set size: {len(test_data)}')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8c046341",
   "metadata": {},
   "source": [
    "## 1.b Avoidance of Information Leakage\n",
    "\n",
    "Measures taken to prevent information leakage between sets:\n",
    "- Ensured samples from the same speaker are only in one set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d7522",
   "metadata": {},
   "source": [
    "## 1.c Deriving Unbiased Performance Estimates\n",
    "\n",
    "Using cross-validation on the training set to obtain unbiased performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f09a2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.447799Z"
    }
   },
   "source": [
    "# Example of cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "print(f'Cross-validation scores: {cv_scores}')\n",
    "print(f'Average CV score: {np.mean(cv_scores)}')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "836c307d",
   "metadata": {},
   "source": [
    "# 2. Classes & Features\n",
    "\n",
    "## 2.a Grouping of Words and \"Other\" Snippets\n",
    "\n",
    "Details on how the 20 keywords and \"Other\" snippets were grouped into classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877027fb",
   "metadata": {},
   "source": [
    "## 2.b Subset of Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e54096",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.451303Z"
    }
   },
   "source": [
    "# Feature selection example\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "X = train_data.drop('label', axis=1)\n",
    "y = train_data['label']\n",
    "\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print('Selected features:', selected_features)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "42394710",
   "metadata": {},
   "source": [
    "## 2.c Preprocessing Steps\n",
    "\n",
    "Applied preprocessing steps include normalization and noise reduction using ICA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f9cf7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.454020Z"
    }
   },
   "source": [
    "# Example of normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Example of ICA\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "ica = FastICA(n_components=10)\n",
    "X_ica = ica.fit_transform(X_scaled)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "226e1f10",
   "metadata": {},
   "source": [
    "# 3. Evaluation\n",
    "\n",
    "## 3.a Chosen Evaluation Criteria\n",
    "\n",
    "Chosen evaluation criteria include accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834b644d",
   "metadata": {},
   "source": [
    "## 3.b Baseline and Best Possible Performance\n",
    "\n",
    "Baseline performance using a simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf63363",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.456962Z"
    }
   },
   "source": [
    "# Baseline model example\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "y_dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "accuracy_baseline = accuracy_score(y_test, y_dummy_pred)\n",
    "print(f'Baseline accuracy: {accuracy_baseline}')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3b636ccc",
   "metadata": {},
   "source": [
    "# 4. Experiments\n",
    "\n",
    "## Random Forest\n",
    "### 4.a Classification Performance with Varying Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd11e6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.459255Z"
    }
   },
   "source": [
    "# Random Forest example\n",
    "param_grid = {'n_estimators': [50, 100, 150], 'max_depth': [10, 20, 30]}\n",
    "rf_scores = []\n",
    "\n",
    "for n in param_grid['n_estimators']:\n",
    "    for d in param_grid['max_depth']:\n",
    "        rf = RandomForestClassifier(n_estimators=n, max_depth=d)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        score = accuracy_score(y_val, y_pred)\n",
    "        rf_scores.append((n, d, score))\n",
    "\n",
    "# Visualize the results\n",
    "rf_df = pd.DataFrame(rf_scores, columns=['n_estimators', 'max_depth', 'accuracy'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=rf_df, x='n_estimators', y='accuracy', hue='max_depth')\n",
    "plt.title('Random Forest Hyperparameter Tuning')\n",
    "plt.savefig('fig/rf_hyperparameter_tuning.png')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "38c5a384",
   "metadata": {},
   "source": [
    "### 4.b Overfitting and Underfitting Analysis\n",
    "\n",
    "Discuss the extent of overfitting or underfitting observed in Random Forest experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db54a2a",
   "metadata": {},
   "source": [
    "### 4.c Final Unbiased Performance Comparison\n",
    "\n",
    "Summarize the results in a comparative table or plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e517c6f",
   "metadata": {},
   "source": [
    "## Nearest Neighbour\n",
    "### 4.a Classification Performance with Varying Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e220bb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.460802Z"
    }
   },
   "source": [
    "# Nearest Neighbour example\n",
    "param_grid = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
    "knn_scores = []\n",
    "\n",
    "for k in param_grid['n_neighbors']:\n",
    "    for w in param_grid['weights']:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights=w)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_val)\n",
    "        score = accuracy_score(y_val, y_pred)\n",
    "        knn_scores.append((k, w, score))\n",
    "\n",
    "# Visualize the results\n",
    "knn_df = pd.DataFrame(knn_scores, columns=['n_neighbors', 'weights', 'accuracy'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=knn_df, x='n_neighbors', y='accuracy', hue='weights')\n",
    "plt.title('K-Nearest Neighbours Hyperparameter Tuning')\n",
    "plt.savefig('fig/knn_hyperparameter_tuning.png')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2f9763fb",
   "metadata": {},
   "source": [
    "### 4.b Overfitting and Underfitting Analysis\n",
    "\n",
    "Discuss the extent of overfitting or underfitting observed in Nearest Neighbour experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c6bf8",
   "metadata": {},
   "source": [
    "### 4.c Final Unbiased Performance Comparison\n",
    "\n",
    "Summarize the results in a comparative table or plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f816ad2",
   "metadata": {},
   "source": [
    "## CNN\n",
    "### 4.a Classification Performance with Varying Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679356d8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.462300Z"
    }
   },
   "source": [
    "# CNN example\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(height, width, channels)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.title('CNN Training History')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('fig/cnn_training_history.png')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1bf9766e",
   "metadata": {},
   "source": [
    "### 4.b Overfitting and Underfitting Analysis\n",
    "\n",
    "Discuss the extent of overfitting or underfitting observed in CNN experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe6068",
   "metadata": {},
   "source": [
    "### 4.c Final Unbiased Performance Comparison\n",
    "\n",
    "Summarize the results in a comparative table or plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a616e6",
   "metadata": {},
   "source": [
    "# 5. Analysis of Realistic Scenes\n",
    "\n",
    "## 5.a Qualitative Evaluation of Best Classifier\n",
    "\n",
    "Listen to the provided scenes and inspect classifier predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc3e88",
   "metadata": {},
   "source": [
    "## 5.b Problematic Conditions and Solutions\n",
    "\n",
    "Identify problematic conditions causing misrecognition or misprediction of keywords. Suggest potential solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef1594",
   "metadata": {},
   "source": [
    "## 5.c Visualization of Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d702d25",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.464268Z"
    }
   },
   "source": [
    "# Example of visualizing predictions on spectrogram\n",
    "import librosa.display\n",
    "\n",
    "audio, sr = librosa.load('example_scene.wav')\n",
    "S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
    "log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.title('Mel-Spectrogram of Example Scene')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.savefig('fig/mel_spectrogram_example_scene.png')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3f5c114f",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Summary of findings and future research directions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
