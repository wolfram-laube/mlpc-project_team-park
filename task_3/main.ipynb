{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533d40b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T14:54:20.904395Z",
     "start_time": "2024-05-20T14:54:20.895964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Any additional libraries needed\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Ensure the 'fig' directory exists\n",
    "import os\n",
    "os.makedirs('fig', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66325eb",
   "metadata": {},
   "source": [
    "# 1. Data Split\n",
    "\n",
    "## 1.a Description of Data Split for Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1caf3597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T11:26:47.448596Z",
     "start_time": "2024-05-20T11:26:46.932316Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Load your dataset\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43myour_dataset.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Split the dataset\u001B[39;00m\n\u001B[1;32m      5\u001B[0m train_data, test_data \u001B[38;5;241m=\u001B[39m train_test_split(data, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    900\u001B[0m     dialect,\n\u001B[1;32m    901\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    909\u001B[0m )\n\u001B[1;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1660\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1661\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1662\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1663\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1664\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1665\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1666\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1668\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1670\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1671\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1672\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/common.py:859\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    854\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    855\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    858\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 859\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    863\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    867\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    868\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'your_dataset.csv'"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Split the dataset\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Description of the data split\n",
    "print(f'Training set size: {len(train_data)}')\n",
    "print(f'Validation set size: {len(val_data)}')\n",
    "print(f'Test set size: {len(test_data)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c046341",
   "metadata": {},
   "source": [
    "## 1.b Avoidance of Information Leakage\n",
    "\n",
    "Measures taken to prevent information leakage between sets:\n",
    "- Ensured samples from the same speaker are only in one set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d7522",
   "metadata": {},
   "source": [
    "## 1.c Deriving Unbiased Performance Estimates\n",
    "\n",
    "Using cross-validation on the training set to obtain unbiased performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f09a2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.447799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "print(f'Cross-validation scores: {cv_scores}')\n",
    "print(f'Average CV score: {np.mean(cv_scores)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836c307d",
   "metadata": {},
   "source": [
    "# 2. Classes & Features\n",
    "\n",
    "## 2.a Grouping of Words and \"Other\" Snippets\n",
    "\n",
    "Details on how the 20 keywords and \"Other\" snippets were grouped into classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877027fb",
   "metadata": {},
   "source": [
    "## 2.b Subset of Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e54096",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.451303Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature selection example\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "X = train_data.drop('label', axis=1)\n",
    "y = train_data['label']\n",
    "\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print('Selected features:', selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42394710",
   "metadata": {},
   "source": [
    "## 2.c Preprocessing Steps\n",
    "\n",
    "Applied preprocessing steps include normalization and noise reduction using ICA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f9cf7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.454020Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Example of ICA\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "ica = FastICA(n_components=10)\n",
    "X_ica = ica.fit_transform(X_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e1f10",
   "metadata": {},
   "source": [
    "# 3. Evaluation\n",
    "\n",
    "## 3.a Chosen Evaluation Criteria\n",
    "\n",
    "Chosen evaluation criteria include accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834b644d",
   "metadata": {},
   "source": [
    "## 3.b Baseline and Best Possible Performance\n",
    "\n",
    "Baseline performance using a simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf63363",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.456962Z"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline model example\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "y_dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "accuracy_baseline = accuracy_score(y_test, y_dummy_pred)\n",
    "print(f'Baseline accuracy: {accuracy_baseline}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b636ccc",
   "metadata": {},
   "source": [
    "# 4. Experiments\n",
    "\n",
    "## Random Forest\n",
    "### 4.a Classification Performance with Varying Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd11e6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.459255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random Forest example\n",
    "param_grid = {'n_estimators': [50, 100, 150], 'max_depth': [10, 20, 30]}\n",
    "rf_scores = []\n",
    "\n",
    "for n in param_grid['n_estimators']:\n",
    "    for d in param_grid['max_depth']:\n",
    "        rf = RandomForestClassifier(n_estimators=n, max_depth=d)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        score = accuracy_score(y_val, y_pred)\n",
    "        rf_scores.append((n, d, score))\n",
    "\n",
    "# Visualize the results\n",
    "rf_df = pd.DataFrame(rf_scores, columns=['n_estimators', 'max_depth', 'accuracy'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=rf_df, x='n_estimators', y='accuracy', hue='max_depth')\n",
    "plt.title('Random Forest Hyperparameter Tuning')\n",
    "plt.savefig('fig/rf_hyperparameter_tuning.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c5a384",
   "metadata": {},
   "source": [
    "### 4.b Overfitting and Underfitting Analysis\n",
    "\n",
    "Discuss the extent of overfitting or underfitting observed in Random Forest experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db54a2a",
   "metadata": {},
   "source": [
    "### 4.c Final Unbiased Performance Comparison\n",
    "\n",
    "Summarize the results in a comparative table or plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e517c6f",
   "metadata": {},
   "source": [
    "## Nearest Neighbour\n",
    "### 4.a Classification Performance with Varying Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e220bb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.460802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Nearest Neighbour example\n",
    "param_grid = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
    "knn_scores = []\n",
    "\n",
    "for k in param_grid['n_neighbors']:\n",
    "    for w in param_grid['weights']:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights=w)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_val)\n",
    "        score = accuracy_score(y_val, y_pred)\n",
    "        knn_scores.append((k, w, score))\n",
    "\n",
    "# Visualize the results\n",
    "knn_df = pd.DataFrame(knn_scores, columns=['n_neighbors', 'weights', 'accuracy'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=knn_df, x='n_neighbors', y='accuracy', hue='weights')\n",
    "plt.title('K-Nearest Neighbours Hyperparameter Tuning')\n",
    "plt.savefig('fig/knn_hyperparameter_tuning.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9763fb",
   "metadata": {},
   "source": [
    "### 4.b Overfitting and Underfitting Analysis\n",
    "\n",
    "Discuss the extent of overfitting or underfitting observed in Nearest Neighbour experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c6bf8",
   "metadata": {},
   "source": [
    "### 4.c Final Unbiased Performance Comparison\n",
    "\n",
    "Summarize the results in a comparative table or plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f816ad2",
   "metadata": {},
   "source": [
    "## CNN\n",
    "### 4.a Classification Performance with Varying Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679356d8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.462300Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN example\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(height, width, channels)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.title('CNN Training History')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('fig/cnn_training_history.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf9766e",
   "metadata": {},
   "source": [
    "### 4.b Overfitting and Underfitting Analysis\n",
    "\n",
    "Discuss the extent of overfitting or underfitting observed in CNN experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe6068",
   "metadata": {},
   "source": [
    "### 4.c Final Unbiased Performance Comparison\n",
    "\n",
    "Summarize the results in a comparative table or plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a616e6",
   "metadata": {},
   "source": [
    "# 5. Analysis of Realistic Scenes\n",
    "\n",
    "## 5.a Qualitative Evaluation of Best Classifier\n",
    "\n",
    "Listen to the provided scenes and inspect classifier predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc3e88",
   "metadata": {},
   "source": [
    "## 5.b Problematic Conditions and Solutions\n",
    "\n",
    "Identify problematic conditions causing misrecognition or misprediction of keywords. Suggest potential solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef1594",
   "metadata": {},
   "source": [
    "## 5.c Visualization of Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d702d25",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T11:26:47.464268Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of visualizing predictions on spectrogram\n",
    "import librosa.display\n",
    "\n",
    "audio, sr = librosa.load('example_scene.wav')\n",
    "S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
    "log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.title('Mel-Spectrogram of Example Scene')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.savefig('fig/mel_spectrogram_example_scene.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c114f",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Summary of findings and future research directions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
